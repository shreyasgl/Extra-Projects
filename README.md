```markdown
# ğŸ§  Multi-Agent AI Classification System

A local, open-source-powered AI system that accepts input in **Email**, **JSON**, or **plain text** format, classifies its **format** and **intent**, routes it to the appropriate agent, and logs results in a shared memory database.

Built with **Flask**, **SQLite**, and **open-source LLMs (Ollama + Mistral)** â€” no OpenAI API key required!

---

## ğŸš€ Features

âœ… Classifies input format: `Email`, `JSON`, or `Text`  
âœ… Determines intent: `Invoice`, `RFQ`, `Complaint`, etc.  
âœ… Routes input to the correct agent:
- **JSON Agent**: Reformat + validate structured JSON
- **Email Agent**: Extract sender, urgency, intent  
âœ… Logs everything in **SQLite** (thread ID, timestamp, source)  
âœ… View logs at: `http://localhost:5000/logs`

---

## ğŸ§± Tech Stack

- ğŸ”¹ Python 3.8+
- ğŸ”¹ Flask
- ğŸ”¹ SQLite (lightweight memory)
- ğŸ”¹ Ollama + Mistral LLM (runs locally)
- ğŸ”¹ Bootstrap (web UI)
- ğŸ”¹ `llama-cpp-python` optional alternative

---

## ğŸ—‚ï¸ Folder Structure

```

multi\_agent\_ai/
â”œâ”€â”€ app.py                 # Flask app
â”œâ”€â”€ classifier\_agent.py    # Uses LLM to detect format and intent
â”œâ”€â”€ json\_agent.py          # Processes and validates JSON
â”œâ”€â”€ email\_agent.py         # Extracts info from emails
â”œâ”€â”€ memory.py              # Shared memory (SQLite)
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html         # Web interface
â”œâ”€â”€ .env                   # For local secrets
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

````

---

## ğŸ“¦ Setup Instructions

### 1. âœ… Install Dependencies

```bash
pip install -r requirements.txt
````

### 2. âœ… Install Ollama & Mistral LLM (Local)

* Download Ollama: [https://ollama.com/download](https://ollama.com/download)
* In terminal:

```bash
ollama run mistral
```

This downloads and runs the `mistral` model locally.

---

### 3. âœ… Run the Flask App

```bash
python app.py
```

Then visit: [http://localhost:5000](http://localhost:5000)

---

## ğŸ§ª Example Inputs

### ğŸ“§ Email Input:

```
From: user@company.com
Please send a quote for 200 units. Urgent.
```

### ğŸ§¾ JSON Input:

```json
{"intent": "Invoice", "name": "ACME Corp", "amount": 1499.99}
```

---

## ğŸ“„ View Logs

Visit: [http://localhost:5000/logs](http://localhost:5000/logs)
All memory logs are stored in `memory.db`

---

## ğŸ“Œ Future Improvements

* [ ] Add PDF parser and PDF Agent
* [ ] Export logs to CSV/JSON
* [ ] Deploy via Docker or Replit
* [ ] Role-based agent chaining
* [ ] Fine-tune LLM on internal classification needs

---

## ğŸ¤ Contributing

Feel free to fork and submit PRs to improve routing logic, add agent types, or suggest better local models.

---

## ğŸ“œ License

MIT License â€” free for personal and commercial use.

---

## ğŸ™Œ Acknowledgments

* [Ollama](https://ollama.com) for local LLM runtime
* [Flask](https://flask.palletsprojects.com/)
* [Mistral](https://huggingface.co/mistralai) for fast open-source LLM

```

---

